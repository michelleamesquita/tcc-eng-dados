[2022-09-11 07:01:07,929] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: tcc_dag.add-db-data manual__2022-09-11T07:00:53.811781+00:00 [queued]>
[2022-09-11 07:01:07,959] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: tcc_dag.add-db-data manual__2022-09-11T07:00:53.811781+00:00 [queued]>
[2022-09-11 07:01:07,962] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2022-09-11 07:01:07,964] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2022-09-11 07:01:07,967] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2022-09-11 07:01:08,015] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): add-db-data> on 2022-09-11 07:00:53.811781+00:00
[2022-09-11 07:01:08,033] {standard_task_runner.py:52} INFO - Started process 13935 to run task
[2022-09-11 07:01:08,041] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'tcc_dag', 'add-db-data', 'manual__2022-09-11T07:00:53.811781+00:00', '--job-id', '510', '--raw', '--subdir', 'DAGS_FOLDER/tcc_dag.py', '--cfg-path', '/tmp/tmpc44aj2tk', '--error-file', '/tmp/tmp1rzyxv67']
[2022-09-11 07:01:08,043] {standard_task_runner.py:80} INFO - Job 510: Subtask add-db-data
[2022-09-11 07:01:08,207] {task_command.py:369} INFO - Running <TaskInstance: tcc_dag.add-db-data manual__2022-09-11T07:00:53.811781+00:00 [running]> on host b6ddae3e9f9e
[2022-09-11 07:01:08,390] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Michelle Mesquita
AIRFLOW_CTX_DAG_ID=tcc_dag
AIRFLOW_CTX_TASK_ID=add-db-data
AIRFLOW_CTX_EXECUTION_DATE=2022-09-11T07:00:53.811781+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-09-11T07:00:53.811781+00:00
[2022-09-11 07:01:40,970] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/tcc_dag.py", line 97, in add_db_data
    df_diff = pd.concat([df_current,df_db]).drop_duplicates(subset=["ds_url_issue","id_vulnerability"],keep=False).reset_index()
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/reshape/concat.py", line 304, in concat
    sort=sort,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/reshape/concat.py", line 384, in __init__
    raise TypeError(msg)
TypeError: cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid
[2022-09-11 07:01:40,986] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=tcc_dag, task_id=add-db-data, execution_date=20220911T070053, start_date=20220911T070107, end_date=20220911T070140
[2022-09-11 07:01:41,000] {standard_task_runner.py:97} ERROR - Failed to execute job 510 for task add-db-data (cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid; 13935)
[2022-09-11 07:01:41,019] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-09-11 07:01:41,049] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
